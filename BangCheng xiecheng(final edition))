# coding: utf-8
# __author__ = "WheeIn"
# __date__ = 2019/07/30 12:00

import os
import time
import xlwt
import itchat
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.keys import Keys


#全局部分
# 微信登录部分
Whether_need_wechat_call = input("是否需要使用微信监视爬虫运行情况？（请输入是/否，建议使用微信小号监视，有小几率会导致微信封号）\n")
if Whether_need_wechat_call == "是":
    print("请在三秒后扫描二维码登录用于监视的微信账号\n")
    time.sleep(3)
    itchat.auto_login()

first = 0
int(first)

#微信监视函数
def warning_in_wechat(n):
    global first
    if first < 3:
        first += 1
        print("已向已登录的微信账号建立了连接\n")
        itchat.send("已经和爬虫脚本建立了连接", toUserName='filehelper')
    else:
        print("已向已登录的微信账号的文件传输助手发送了监视信息\n")
        itchat.send(str(n), toUserName='filehelper')


#函数修饰器实现的重试函数
def retry(times=1, exceptions=None):
    exceptions = exceptions if exceptions is not None else Exception
    if Whether_need_wechat_call == "是":
        n_wrong = "爬虫报错了，正在重试中......"
        warning_in_wechat(n_wrong)

    def wrapper(func):
        def wrapper(*args, **kwargs):
            last_exception =None
            for _ in range(times):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
            raise last_exception
        return wrapper
    return wrapper


#爬取客车数据函数
@retry(5)
def bus_capture():
    for Date in Dates_lists:
        try:
            # 在Path下创建一个以日期_客车数据为名称的文件夹
            os.makedirs(Path + '\\' + Date + "_客车数据")
        except IOError:
            print("该路径已存在，请更换路径")
        else:
            for From_list in From_lists:
                From_ = From_list  # 将出发点名称赋值给变量From_，并且进行强制类型转换
                for To_list in To_lists:
                    # url请求部分
                    To_ = To_list
                    # 输入爬取请求的url_req = requests.get(url)
                    url = "https://bus.ctrip.com/busListn.html?from={0}&from_city_id={0}&to={1}&to_city_id={1}&date={2}".format(
                        From_
                        , To_
                        , Date)
                    print("正在爬取：" + url)
                    # 打开火狐浏览器（需提前安装好geckodriver）
                    browser = webdriver.Firefox()
                    print("正在打开网页...")
                    browser.get(url)
                    print("等待网页响应...")
                    # 需要等一下，直到页面加载完成
                    js = "window.scrollTo(0, document.body.scrollHeight)"  # 滑动滚动条到底部
                    # 多次下滑
                    for Level_Index in range(Level_Indexes):
                        browser.execute_script(js)
                        time.sleep(Lay_back)
                    print("正在获取网页数据...")
                    time.sleep(3)
                    # 等浏览器下滑到底，再开始抓时间
                    content = browser.page_source.encode('utf-8')
                    # 解析HTMl文件
                    soup = BeautifulSoup(content, "lxml")
                    Times = soup.find_all('span', 'railway_time')
                    Prices = soup.find_all('span', 'base_price base_full_price')
                    SE_station = soup.find_all('td')
                    Remains = soup.find_all('td', 'text_right')
                    # 判断语句，不生成空表
                    if len(Times) != 0:
                        # 制表
                        workbook = xlwt.Workbook()
                        sheet = workbook.add_sheet('车票情况', cell_overwrite_ok=True)  # 将sheet表取名为车票情况
                        sheet.write(0, 0, '时间')  # 在第一行第一列的第一格写入 ‘时间’
                        sheet.write(0, 1, '始发站和终点站')  # 在第一行第二列的第一格写入 ‘始发站与终点站’
                        sheet.write(0, 2, '票价')# 在第一行第三列的第一格写入 ‘票价’
                        sheet.write(0, 3, '余票')
                        sheet.write(0, 4, '车辆信息和预计耗时')
                        Indexes = len(Times)
                        # 各种控制量,判断语句用于规避携程的弱智的广告
                        if "火车票" not in str(SE_station[0].text):
                            Index = 0  # 重置excel的行控制量
                            SE_Index = 1  # 重置html中xpath的SE控制量
                            Bus_Index = 2  ##重置html中xpath的车辆信息控制量
                        else:
                            Index = 0  # 重置excel的行控制量
                            SE_Index = 5  # 重置html中xpath的SE控制量
                            Bus_Index = 6  ##重置html中xpath的车辆信息控制量
                        for Index in range(Indexes):
                            sheet.write(Index + 1, 0, Times[Index].text)  # 写入时间
                            sheet.write(Index + 1, 1, SE_station[SE_Index].text)  # 写入始发终点站
                            sheet.write(Index + 1, 2, float(Prices[Index].text))
                            sheet.write(Index + 1, 3, Remains[Index].text)
                            sheet.write(Index + 1, 4, SE_station[Bus_Index].text)  # 车辆信息和预计耗时
                            Index += 1
                            SE_Index += 6 #反正就是刚好个六个六个就是始发终点站的信息
                            Bus_Index += 6
                    else:
                        # 跳出本次循环，不生成表
                        print("【警告】{}，从{}到{}暂无可售车票！".format(Date, From_, To_))
                        browser.close()
                        continue
                    # 保存整个表
                    workbook.save(Path + '\\' + Date + "_客车数据" + '\\' + Date + From_ + '到' + To_ + '_客车数据.xls')  # 再保存
                    browser.close()
            print("所有客车数据已经放在了" + Path + "\\" + Date + "_客车数据" + "文件夹下")

#爬取火车动车数据函数
@retry(5)
def train_capture():
    for Date in Dates_lists:
        try:
            # 在Path下创建一个以日期_客车数据为名称的文件夹
            os.makedirs(Path + '\\' + Date + "_动车数据")
        except IOError:
            print("该路径已存在，请更换路径")
        else:
            for From_list in From_lists:
                From_ = From_list  # 将出发点名称赋值给变量From_，并且进行强制类型转换
                for To_list in To_lists:
                    To_ = To_list
                    # url请求部分,以2019-07-30，北京到北京的网页作为初始搜索页面，如果这个网页失效了，可以将其替换
                    url = "https://trains.ctrip.com/TrainBooking/Search.aspx?from=beijing&to=beijing&day=2019-07-30&num\
                    ber=&fromCn=%25E5%258C%2597%25E4%25BA%25AC&toCn=%25E5%258C%2597%25E4%25BA%25AC"
                    browser = webdriver.Firefox()
                    print("正在打开网页...")
                    browser.get(url)
                    #s：出发点，e：终点，t：时间    火狐Xpath定位
                    input_element_s = browser.find_element_by_xpath("//*[@id='notice01']")
                    input_element_s.clear()
                    time.sleep(0.5)
                    input_element_s.send_keys(From_)
                    time.sleep(0.5)
                    input_element_e = browser.find_element_by_xpath("//*[@id='notice08']")
                    input_element_e.clear()
                    time.sleep(0.5)
                    input_element_e.send_keys(To_)
                    time.sleep(0.5)
                    input_element_t = browser.find_element_by_xpath("//*[@id='dateObj']")
                    input_element_t.clear()
                    time.sleep(0.5)
                    input_element_t.send_keys(Date)
                    time.sleep(0.5) 
                    input_element_t.send_keys(Keys.ENTER)
                    time.sleep(1)
                    js = "window.scrollTo(0, document.body.scrollHeight)"  # 滑动滚动条到底部
                    # 多次下滑
                    #火车下滑次数不需要太多
                    Train_Level_Indexes = int((Level_Indexes/10)+1)
                    for train_Level_Index in range(Train_Level_Indexes):
                        browser.execute_script(js)
                        time.sleep(Lay_back)
                    time.sleep(3)
                    content = browser.page_source
                    # 解析HTMl文件
                    soup = BeautifulSoup(content, "lxml")
                    Train_num = soup.find_all('div', 'w1')#车次
                    Train_Start_Times = soup.find_all('div', 'w2')#发车时间和始发站
                    Train_End_Times = soup.find_all('div', 'w3')#到达时间和终点站
                    Take_time = soup.find_all('div', 'w4')#耗时
                    Ticket = soup.find_all('div', 'w5')# 票价和余票（二等座，一等座，商务座）
                    
                    if len(Train_Start_Times) != 0:
                        # 制表
                        workbook = xlwt.Workbook()
                        sheet = workbook.add_sheet('车票情况', cell_overwrite_ok=True)  # 将sheet表取名为车票情况
                        sheet.write(0, 0, '车次')  # 在第一行第一列的第一格写入 “车次”
                        sheet.write(0, 1, '发车时间和始发站')  # 在第一行第二列的第一格写入 ‘出发时间和始发站’
                        sheet.write(0, 2, '到达时间和终点站')# 在第一行第三列的第一格写入 '到达时间和终点站'
                        sheet.write(0, 3, '预计耗时')
                        sheet.write(0, 4, '票价和余票（二等座，一等座，商务座）')
                        Indexes = len(Train_num)
                        Index = 0
                        for Index in range(Indexes):
                            sheet.write(Index + 1, 0, Train_num[Index].text)  # 写入车次
                            sheet.write(Index + 1, 1, Train_Start_Times[Index].text)  # 写入出发时间和始发站
                            sheet.write(Index + 1, 2, Train_End_Times[Index].text)
                            sheet.write(Index + 1, 3, Take_time[Index].text)
                            sheet.write(Index + 1, 4, Ticket[Index].text)  # 车辆信息和预计耗时
                            Index += 1
                    else:
                        # 跳出本次循环，不生成表
                        print("【警告】{}，从{}到{}暂无可售车票！".format(Date, From_, To_))
                        browser.close()
                        continue
                    # 保存整个表
                    workbook.save(Path + '\\' + Date + "_动车数据" + '\\' + Date + From_ + '到' + To_ + '_动车数据.xls')  # 再保存
                    browser.close()
            print("所有动车数据已经放在了" + Path + "\\" + Date + "_动车数据" + "文件夹下")


#爬取飞机数据函数
@retry(5)
def aircraft_capture():
    for Date in Dates_lists:                                                             
        try:                                                                             
            # 在Path下创建一个以日期_客车数据为名称的文件夹                                                                        
            os.makedirs(Path + '\\' + Date + "_机票数据")
        except IOError:                                                                                         
            print("该路径已存在，请更换路径")                                                                               
        else:                                                                                                   
            for From_list in From_lists:                                                                        
                From_ = From_list  # 将出发点名称赋值给变量From_，并且进行强制类型转换                                                
                for To_list in To_lists:                                                                        
                    # url请求部分                                                                                   
                    To_ = To_list                                                                               
                    # url请求部分,以携程网国内的飞机票搜索页面为开始搜索的页面
                    url = "https://flights.ctrip.com/"
                    browser = webdriver.Firefox()
                    print("正在打开网页...")
                    browser.get(url)
                    time.sleep(3)
                    AC_element_s = browser.find_element_by_xpath("//*[@id='DepartCity1TextBox']")
                    AC_element_s.clear()
                    time.sleep(0.5)
                    AC_element_s.send_keys(From_)
                    time.sleep(0.5)
                    AC_element_e = browser.find_element_by_xpath("//*[@id='ArriveCity1TextBox']")
                    AC_element_e.clear()
                    time.sleep(0.5)
                    AC_element_e.send_keys(To_)
                    time.sleep(0.5)
                    AC_element_t = browser.find_element_by_xpath("//*[@id='DepartDate1TextBox']")
                    AC_element_t.clear()
                    time.sleep(0.5)
                    AC_element_t.send_keys(Date)
                    time.sleep(0.5)
                    AC_element_t.send_keys(Keys.ENTER)
                    time.sleep(1)
                    js = "window.scrollTo(0, document.body.scrollHeight)"  # 滑动滚动条到底部
                    # 多次下滑
                    #飞机下滑次数不需要太多
                    AC_Level_Indexes = int((Level_Indexes/10)+1)
                    for train_Level_Index in range(AC_Level_Indexes):
                        browser.execute_script(js)
                        time.sleep(Lay_back)
                    time.sleep(3)
                    content = browser.page_source
                    # 解析HTMl文件
                    soup = BeautifulSoup(content, "lxml")
                    AC_num = soup.find_all('div', 'logo-item flight_logo')#公司以及航班号
                    AC_start = soup.find_all('div', 'inb right')#起飞时间（列表中的偶数对象）和降落时间（奇数对象）
                    AC_end = soup.find_all('div', 'inb left')#起飞机场（列表中的偶数对象）和到达机场（奇数对象）
                    AC_right_time = soup.find_all('div', 'service-item')#准点率
                    if len(AC_num) != 0:
                        # 制表
                        workbook = xlwt.Workbook()
                        sheet = workbook.add_sheet('机票情况', cell_overwrite_ok=True)  # 将sheet表取名为机票情况
                        sheet.write(0, 0, '公司以及航班号')  # 在第一行第一列的第一格写入 “公司以及航班号”
                        sheet.write(0, 1, '起飞时间和起飞机场')  # 在第一行第二列的第一格写入 ‘起飞时间和起飞机场’
                        sheet.write(0, 2, '到达时间和到达机场')# 在第一行第三列的第一格写入 '到达时间和到达机场'
                        sheet.write(0, 3, '准点率')
                        Indexes = len(AC_start)
                        Index = 0
                        for Index in range(Indexes):
                            sheet.write(Index + 1, 0, AC_num[Index].text)  # 写入公司以及航班号
                            sheet.write(Index + 1, 1, AC_start[Index].text)  # 写入出发信息
                            sheet.write(Index + 1, 2, AC_end[Index].text)#到达信息
                            sheet.write(Index + 1, 3, AC_right_time[Index].text)  # 准点率
                            Index += 1
                    else:
                        # 跳出本次循环，不生成表
                        print("【警告】{}，从{}到{}暂无可售机票！".format(Date, From_, To_))
                        browser.close()
                        continue
                    # 保存整个表
                    workbook.save(Path + '\\' + Date + "_机票数据" + '\\' + Date + From_ + '到' + To_ + '_机票数据.xls')  # 再保存
                    browser.close()
            print("所有机票数据已经放在了" + Path + "\\" + Date + "_机票数据" + "文件夹下")


#运行主函数，作为模块被外部引入时不会执行
if __name__ == '__main__':
    #输入部分
    #输入需要查询的日期，将日期赋值
    type = input("请输入需要爬取的是什么类型的客运数据？（请填入其中之一： 客车、动车、飞机、全部)\n")
    Path = input("请输入存放数据的路径，如C:\\Users\\WheeIn\\Desktop\\XieChengQiChe\n")
    Level_Indexes = int(input("请输入搜索强度（1~100的整数），数值越高数据爬取得越精细，爬取的耗时也会变长\n"))
    Lay_back = float(input("请输入响应延迟，（0.5~5秒），网络不佳时请输入较大的响应延迟\n"))
    Dates_lists_size = int(input("请输入需要爬多少天的数据？\n"))
    From_lists_size = int(input("请输入一共有多少个起点\n"))
    To_lists_size = int(input("请输入一共有多少个终点\n"))

    #始发站点和终点站点的列表部分
    From_lists = []
    To_lists = []
    Dates_lists = []
    DS = 1
    FS = 1
    TS = 1

    #参数输入部分
    #日期输入列表部分
    for DS in range(Dates_lists_size):
        Dates = input("请输入需要查询的日期(格式：2019-07-16)\n")
        Dates_lists.append(Dates)
        DS += 1
    #起点终点输入部分
    for FS in range(From_lists_size):
        Start_point = input("请输入需要查询的起点\n")
        From_lists.append(Start_point)
        FS += 1

    for TS in range(To_lists_size):
        End_point = input("请输入需要查询的终点\n")
        To_lists.append(End_point)
        TS += 1
    # 正式开爬
    if type == "全部":
        bus_capture()
        train_capture()
        aircraft_capture()
    else:
        if type == "客车":
            bus_capture()
        elif type == "动车":
            train_capture()
        elif type == "飞机":
            aircraft_capture()
        else:
            print("请输入正确的客运方式\n")

    if Whether_need_wechat_call == "是":
        news = "爬虫任务已完成，请到相应的目录下查看数据"
        warning_in_wechat(news)

    #按任意键继续
    os.system('pause\n')
